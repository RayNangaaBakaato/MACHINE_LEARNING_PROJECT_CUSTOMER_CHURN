# MACHINE_LEARNING_PROJECT_CUSTOMER_CHURN

# ğŸ§  Predicting Customers Churn with Machine Learning

### ğŸ“ Real-World Classification Project | Data Science Portfolio by  Ray NANGAA BAKAATO MANGALAZA

## ğŸš€ Project Overview

In this end-to-end machine learning project, I tackled a real-world customer retention problem using classification modeling. The goal was to accurately **predict customer churn** â€” identifying which customers are most likely to leave a service or subscription based on their behavior, demographics, and interactions.

I implemented this using the **RAY Framework**, which guides projects from raw data to meaningful business insights, emphasizing model performance, interpretability, and communication.

---

## ğŸ¯ Problem Statement

The challenge was to build a model that can **predict whether a customer will churn** (yes/no) based on features like **tenure, monthly charges, service types, and payment method**.

Understanding churn helps businesses take **preventive actions**, increase **customer retention**, and reduce **revenue loss**.

---

## ğŸ“Š Dataset Summary

- âœ… Rows: `7,043`
- âœ… Features: `21` columns (after cleaning)
- âœ… Target: `Churn` (binary: Yes/No)
- âœ… Source: [Telco Customer Churn dataset](https://www.kaggle.com/blastchar/telco-customer-churn)

---

## ğŸ› ï¸ Tools & Libraries Used

- **Python**, **Pandas**, **NumPy**
- **Scikit-learn**, **XGBoost**, **Matplotlib**, **Seaborn**
- **SHAP** for model explainability
- **Joblib** for saving models
- **Jupyter Notebook** for reproducibility and storytelling

---



# ğŸ” Key Steps & Highlights

### 1. Exploratory Data Analysis (EDA)
	â€¢	Uncovered class imbalance in churn (~27%)
	â€¢	Explored correlations between tenure, charges, and churn
	â€¢	Detected feature leakage and handled categorical encoding

### 2. Model Training & Comparison
	â€¢	Trained multiple models: Logistic Regression, Random Forest, XGBoost, KNN, SVM
	â€¢	Evaluated using AUC Score for better insight with imbalanced data
	â€¢	Selected top 3 models for tuning

### 3. Hyperparameter Tuning
	â€¢	Tuned models using GridSearchCV and RandomizedSearchCV
	â€¢	Best model: âœ… Random Forest with AUC = 0.91

### 4. Model Explainability
	â€¢	Used feature importance and SHAP to explain model decisions
	â€¢	Top churn predictors: Contract Type, Tenure, Monthly Charges

### 5. Packaging & Deployment
	â€¢	Saved model using joblib
	â€¢	Notebook is clean, reproducible, and designed for technical portfolio showcase

â¸»

## ğŸ“ˆ Results Summary

### Model	AUC Score
- Logistic Regression	0.84
- Random Forest	0.91 âœ…
- XGBoost	0.89

The Random Forest model gave the best balance of accuracy and interpretability. It allows business users to understand why churn is likely to happen, not just that it will.

â¸»

## ğŸ’¡ What I Learned
	â€¢	How to run a complete ML pipeline from EDA to deployment
	â€¢	Importance of proper evaluation metrics (AUC over accuracy)
	â€¢	How to explain model decisions with SHAP
	â€¢	How to communicate complex workflows in a clean, professional notebook

â¸»

ğŸ“¬ Letâ€™s Connect

Iâ€™d love to hear from you!

Contact me: 
- LinkedIn: www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=ray-n-bakaato-mangalaza-292b93169
- Email: raybakaato@gmail.com
- Phone: +39 351 4727302











